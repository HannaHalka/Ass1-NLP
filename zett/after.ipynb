{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14592870,"sourceType":"datasetVersion","datasetId":9321449},{"sourceId":14643928,"sourceType":"datasetVersion","datasetId":9354574},{"sourceId":14700066,"sourceType":"datasetVersion","datasetId":9390990},{"sourceId":737760,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":562600,"modelId":575190},{"sourceId":738787,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":563439,"modelId":575960}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:00:02.418069Z","iopub.execute_input":"2026-02-02T15:00:02.418346Z","iopub.status.idle":"2026-02-02T15:00:03.875738Z","shell.execute_reply.started":"2026-02-02T15:00:02.418316Z","shell.execute_reply":"2026-02-02T15:00:03.874970Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"lang-uk/malyuk\", split=\"train\", streaming=True)\n# dataset = dataset[:300000}\n\ntext = []\nfor i, row in enumerate(dataset['text']):\n    if i > 100000:\n        break\n    text.append(row)\n\n# text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:00:03.877247Z","iopub.execute_input":"2026-02-02T15:00:03.877555Z","iopub.status.idle":"2026-02-02T15:00:27.151153Z","shell.execute_reply.started":"2026-02-02T15:00:03.877534Z","shell.execute_reply":"2026-02-02T15:00:27.150333Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2c087cfcecd4ce68616f3923e085129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/237 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8160f008a7480f83e02ca4e6e0c33e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/237 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"885033d7fe004c61be13952a3d01587b"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:00:27.152107Z","iopub.execute_input":"2026-02-02T15:00:27.152576Z","iopub.status.idle":"2026-02-02T15:00:27.398090Z","shell.execute_reply.started":"2026-02-02T15:00:27.152553Z","shell.execute_reply":"2026-02-02T15:00:27.397151Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Training base vocab","metadata":{}},{"cell_type":"code","source":"from tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom tokenizers.trainers import BpeTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\nfrom transformers import PreTrainedTokenizerFast\n\n# text = court[0].astype(str).tolist()\ntok = Tokenizer(BPE(unk_token=\"<unk>\"))\ntok.pre_tokenizer = Whitespace()\n\ntrainer = BpeTrainer(\n    vocab_size=40000,\n    min_frequency=2,\n    special_tokens=[\"<s>\", \"</s>\", \"<pad>\", \"<unk>\", \"<mask>\"]\n)\n\ntok.train_from_iterator(text, trainer=trainer)\n\ntokA = PreTrainedTokenizerFast(\n    tokenizer_object=tok,\n    bos_token=\"<s>\", eos_token=\"</s>\",\n    unk_token=\"<unk>\", sep_token=\"</s>\",\n    cls_token=\"<s>\", pad_token=\"<pad>\", mask_token=\"<mask>\",\n)\n\ntokA.save_pretrained(\"tokA\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:00:27.399091Z","iopub.execute_input":"2026-02-02T15:00:27.399497Z","iopub.status.idle":"2026-02-02T15:00:48.519647Z","shell.execute_reply.started":"2026-02-02T15:00:27.399465Z","shell.execute_reply":"2026-02-02T15:00:48.519079Z"}},"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"('tokA/tokenizer_config.json',\n 'tokA/special_tokens_map.json',\n 'tokA/tokenizer.json')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokA = AutoTokenizer.from_pretrained(\"/kaggle/working/tokA\", use_fast=True)\nvocab = tokA.get_vocab()\ntokens = [t for t, _id in sorted(vocab.items(), key=lambda x: x[1])]\ntokens[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:00:48.520517Z","iopub.execute_input":"2026-02-02T15:00:48.521035Z","iopub.status.idle":"2026-02-02T15:00:53.788577Z","shell.execute_reply.started":"2026-02-02T15:00:48.521011Z","shell.execute_reply":"2026-02-02T15:00:53.788011Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['<s>', '</s>', '<pad>', '<unk>', '<mask>', '!', '\"', '#', '$', '%']"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"Due to problen with \"from zett.utils import get_surface_form_matrix\" we tokk function \"get_surface_form_matrix\" from Zett repo in GitHub.","metadata":{}},{"cell_type":"code","source":"CHARS_TO_BYTES = {\n    \"Ā\": 0,\n    \"ā\": 1,\n    \"Ă\": 2,\n    \"ă\": 3,\n    \"Ą\": 4,\n    \"ą\": 5,\n    \"Ć\": 6,\n    \"ć\": 7,\n    \"Ĉ\": 8,\n    \"ĉ\": 9,\n    \"Ċ\": 10,\n    \"ċ\": 11,\n    \"Č\": 12,\n    \"č\": 13,\n    \"Ď\": 14,\n    \"ď\": 15,\n    \"Đ\": 16,\n    \"đ\": 17,\n    \"Ē\": 18,\n    \"ē\": 19,\n    \"Ĕ\": 20,\n    \"ĕ\": 21,\n    \"Ė\": 22,\n    \"ė\": 23,\n    \"Ę\": 24,\n    \"ę\": 25,\n    \"Ě\": 26,\n    \"ě\": 27,\n    \"Ĝ\": 28,\n    \"ĝ\": 29,\n    \"Ğ\": 30,\n    \"ğ\": 31,\n    \"Ġ\": 32,\n    \"!\": 33,\n    '\"': 34,\n    \"#\": 35,\n    \"$\": 36,\n    \"%\": 37,\n    \"&\": 38,\n    \"'\": 39,\n    \"(\": 40,\n    \")\": 41,\n    \"*\": 42,\n    \"+\": 43,\n    \",\": 44,\n    \"-\": 45,\n    \".\": 46,\n    \"/\": 47,\n    \"0\": 48,\n    \"1\": 49,\n    \"2\": 50,\n    \"3\": 51,\n    \"4\": 52,\n    \"5\": 53,\n    \"6\": 54,\n    \"7\": 55,\n    \"8\": 56,\n    \"9\": 57,\n    \":\": 58,\n    \";\": 59,\n    \"<\": 60,\n    \"=\": 61,\n    \">\": 62,\n    \"?\": 63,\n    \"@\": 64,\n    \"A\": 65,\n    \"B\": 66,\n    \"C\": 67,\n    \"D\": 68,\n    \"E\": 69,\n    \"F\": 70,\n    \"G\": 71,\n    \"H\": 72,\n    \"I\": 73,\n    \"J\": 74,\n    \"K\": 75,\n    \"L\": 76,\n    \"M\": 77,\n    \"N\": 78,\n    \"O\": 79,\n    \"P\": 80,\n    \"Q\": 81,\n    \"R\": 82,\n    \"S\": 83,\n    \"T\": 84,\n    \"U\": 85,\n    \"V\": 86,\n    \"W\": 87,\n    \"X\": 88,\n    \"Y\": 89,\n    \"Z\": 90,\n    \"[\": 91,\n    \"\\\\\": 92,\n    \"]\": 93,\n    \"^\": 94,\n    \"_\": 95,\n    \"`\": 96,\n    \"a\": 97,\n    \"b\": 98,\n    \"c\": 99,\n    \"d\": 100,\n    \"e\": 101,\n    \"f\": 102,\n    \"g\": 103,\n    \"h\": 104,\n    \"i\": 105,\n    \"j\": 106,\n    \"k\": 107,\n    \"l\": 108,\n    \"m\": 109,\n    \"n\": 110,\n    \"o\": 111,\n    \"p\": 112,\n    \"q\": 113,\n    \"r\": 114,\n    \"s\": 115,\n    \"t\": 116,\n    \"u\": 117,\n    \"v\": 118,\n    \"w\": 119,\n    \"x\": 120,\n    \"y\": 121,\n    \"z\": 122,\n    \"{\": 123,\n    \"|\": 124,\n    \"}\": 125,\n    \"~\": 126,\n    \"ġ\": 127,\n    \"Ģ\": 128,\n    \"ģ\": 129,\n    \"Ĥ\": 130,\n    \"ĥ\": 131,\n    \"Ħ\": 132,\n    \"ħ\": 133,\n    \"Ĩ\": 134,\n    \"ĩ\": 135,\n    \"Ī\": 136,\n    \"ī\": 137,\n    \"Ĭ\": 138,\n    \"ĭ\": 139,\n    \"Į\": 140,\n    \"į\": 141,\n    \"İ\": 142,\n    \"ı\": 143,\n    \"Ĳ\": 144,\n    \"ĳ\": 145,\n    \"Ĵ\": 146,\n    \"ĵ\": 147,\n    \"Ķ\": 148,\n    \"ķ\": 149,\n    \"ĸ\": 150,\n    \"Ĺ\": 151,\n    \"ĺ\": 152,\n    \"Ļ\": 153,\n    \"ļ\": 154,\n    \"Ľ\": 155,\n    \"ľ\": 156,\n    \"Ŀ\": 157,\n    \"ŀ\": 158,\n    \"Ł\": 159,\n    \"ł\": 160,\n    \"¡\": 161,\n    \"¢\": 162,\n    \"£\": 163,\n    \"¤\": 164,\n    \"¥\": 165,\n    \"¦\": 166,\n    \"§\": 167,\n    \"¨\": 168,\n    \"©\": 169,\n    \"ª\": 170,\n    \"«\": 171,\n    \"¬\": 172,\n    \"Ń\": 173,\n    \"®\": 174,\n    \"¯\": 175,\n    \"°\": 176,\n    \"±\": 177,\n    \"²\": 178,\n    \"³\": 179,\n    \"´\": 180,\n    \"µ\": 181,\n    \"¶\": 182,\n    \"·\": 183,\n    \"¸\": 184,\n    \"¹\": 185,\n    \"º\": 186,\n    \"»\": 187,\n    \"¼\": 188,\n    \"½\": 189,\n    \"¾\": 190,\n    \"¿\": 191,\n    \"À\": 192,\n    \"Á\": 193,\n    \"Â\": 194,\n    \"Ã\": 195,\n    \"Ä\": 196,\n    \"Å\": 197,\n    \"Æ\": 198,\n    \"Ç\": 199,\n    \"È\": 200,\n    \"É\": 201,\n    \"Ê\": 202,\n    \"Ë\": 203,\n    \"Ì\": 204,\n    \"Í\": 205,\n    \"Î\": 206,\n    \"Ï\": 207,\n    \"Ð\": 208,\n    \"Ñ\": 209,\n    \"Ò\": 210,\n    \"Ó\": 211,\n    \"Ô\": 212,\n    \"Õ\": 213,\n    \"Ö\": 214,\n    \"×\": 215,\n    \"Ø\": 216,\n    \"Ù\": 217,\n    \"Ú\": 218,\n    \"Û\": 219,\n    \"Ü\": 220,\n    \"Ý\": 221,\n    \"Þ\": 222,\n    \"ß\": 223,\n    \"à\": 224,\n    \"á\": 225,\n    \"â\": 226,\n    \"ã\": 227,\n    \"ä\": 228,\n    \"å\": 229,\n    \"æ\": 230,\n    \"ç\": 231,\n    \"è\": 232,\n    \"é\": 233,\n    \"ê\": 234,\n    \"ë\": 235,\n    \"ì\": 236,\n    \"í\": 237,\n    \"î\": 238,\n    \"ï\": 239,\n    \"ð\": 240,\n    \"ñ\": 241,\n    \"ò\": 242,\n    \"ó\": 243,\n    \"ô\": 244,\n    \"õ\": 245,\n    \"ö\": 246,\n    \"÷\": 247,\n    \"ø\": 248,\n    \"ù\": 249,\n    \"ú\": 250,\n    \"û\": 251,\n    \"ü\": 252,\n    \"ý\": 253,\n    \"þ\": 254,\n    \"ÿ\": 255,\n}\nBYTES_TO_CHARS = {v: k for k, v in CHARS_TO_BYTES.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:00:53.789653Z","iopub.execute_input":"2026-02-02T15:00:53.790393Z","iopub.status.idle":"2026-02-02T15:00:53.808399Z","shell.execute_reply.started":"2026-02-02T15:00:53.790366Z","shell.execute_reply":"2026-02-02T15:00:53.807708Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"MAX_CHARS_PER_TOKEN = 16\n\ndef unicode_to_zett_bytechars(token: str, maxlen: int = MAX_CHARS_PER_TOKEN) -> str:\n    b = token.encode(\"utf-8\", errors=\"replace\")[:maxlen]\n    return \"\".join(BYTES_TO_CHARS[byte] for byte in b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:00:53.810504Z","iopub.execute_input":"2026-02-02T15:00:53.810795Z","iopub.status.idle":"2026-02-02T15:00:53.823549Z","shell.execute_reply.started":"2026-02-02T15:00:53.810756Z","shell.execute_reply":"2026-02-02T15:00:53.822897Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from tqdm.auto import tqdm\nfrom transformers import ByT5Tokenizer\n\ndef get_surface_form_matrix(\n    tokenizer_or_tokens, maxlen, tokenizer_to_use=None, padding=0, verbose=False\n):\n    # tokens are expected to be byte encoded\n    if isinstance(tokenizer_or_tokens, list):\n        tokens = tokenizer_or_tokens\n    else:\n        tokenizer = tokenizer_or_tokens\n        tokens = tokenizer.convert_ids_to_tokens(range(len(tokenizer)))\n\n    vocab_size = len(tokens)\n    surface_form_matrix = np.full(\n        (vocab_size + padding, maxlen),\n        tokenizer_to_use.pad_token_id if tokenizer_to_use is not None else 0,\n        dtype=np.int32,\n    )\n\n    n_truncated = 0\n\n    for i, token in tqdm(enumerate(tokens), total=vocab_size, disable=not verbose):\n        if token in tokenizer_to_use.all_special_tokens:\n            surface_form_matrix[i, 0] = tokenizer_to_use.convert_tokens_to_ids(token)\n            continue\n\n        token = unicode_to_zett_bytechars(token, maxlen=maxlen)\n        token_bytes = bytes([CHARS_TO_BYTES[c] for c in token])\n\n        if isinstance(tokenizer_to_use, ByT5Tokenizer):\n            ids = tokenizer_to_use.convert_tokens_to_ids([chr(i) for i in token_bytes])\n        else:\n            # assume hn tokenizer uses byte pretokenization\n            ids = [x.id for x in tokenizer_to_use._tokenizer.model.tokenize(token)]\n\n        if len(ids) > maxlen:\n            ids = ids[:maxlen]\n            n_truncated += 1\n\n        surface_form_matrix[i, : len(ids)] = ids\n\n    return surface_form_matrix, n_truncated","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:00:53.824403Z","iopub.execute_input":"2026-02-02T15:00:53.824667Z","iopub.status.idle":"2026-02-02T15:00:53.840212Z","shell.execute_reply.started":"2026-02-02T15:00:53.824645Z","shell.execute_reply":"2026-02-02T15:00:53.839542Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer, AutoModelForMaskedLM\n# from zett.utils import get_surface_form_matrix\n\nbase_model = AutoModelForMaskedLM.from_pretrained(\"FacebookAI/xlm-roberta-base\").to(device).eval()\nhypernet = AutoModel.from_pretrained(\"benjamin/zett-hypernetwork-xlm-roberta-base\", trust_remote_code=True).to(device).eval()\n\nhn_tokenizer = AutoTokenizer.from_pretrained(\"benjamin/zett-hypernetwork-xlm-roberta-base\")\n\nsource_embeddings = base_model.get_input_embeddings().weight.detach()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:00:53.841369Z","iopub.execute_input":"2026-02-02T15:00:53.841599Z","iopub.status.idle":"2026-02-02T15:01:20.416300Z","shell.execute_reply.started":"2026-02-02T15:00:53.841577Z","shell.execute_reply":"2026-02-02T15:01:20.415014Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9311e6e6d54240969c204daa00faeb84"}},"metadata":{}},{"name":"stderr","text":"2026-02-02 15:00:56.797196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770044457.016295      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770044457.074298      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770044457.587679      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770044457.587741      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770044457.587765      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770044457.587770      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08d4473fd02e482f8fab2385de97e2fb"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbfe19e7a8114465b897755e16ebbd77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_hypernet.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97937516ce74489d8798c4d139bd649e"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/benjamin/zett-hypernetwork-xlm-roberta-base:\n- configuration_hypernet.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_hypernet.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43fe8615fe844b98ae777384d13b70f0"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/benjamin/zett-hypernetwork-xlm-roberta-base:\n- modeling_hypernet.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/82.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac2293c0a9ce42adbe6c8c5e57a84c48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8cacc627384f4588fd55971e9d03cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a561fef4eb8d40b4bb5040f594348f94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/18.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b138bad99e946c19fd99b00ac7a569d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a29b9a4a31814b61aa05f8f41c567eb5"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"pred_in_chunks = []\n\nfor i in range(0, len(tokens), 512):\n    batch_tokens = tokens[i:i+512]\n\n    target_surface_forms, _ = get_surface_form_matrix(\n        batch_tokens, # byte representation of the tokens to predict\n        maxlen=hypernet.config.hn_surface_maxlen,\n        tokenizer_to_use=hn_tokenizer,\n    )\n\n    lang_index = torch.tensor([17], device=device, dtype=torch.long)\n    with torch.no_grad():\n        # the last output is the predicted bias in case the model uses a bias (e.g. XLM-R)\n        predicted_input_embeddings, predicted_output_embeddings, _ = hypernet(\n            torch.from_numpy(target_surface_forms).to(device),\n            source_embeddings=source_embeddings,\n            lang_index=lang_index\n        )\n\n    pred_in_chunks.append(predicted_input_embeddings.detach().cpu())\n\npredicted_input_embeddings = torch.cat(pred_in_chunks, dim=0) # shap: [40000, 768]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:01:20.417422Z","iopub.execute_input":"2026-02-02T15:01:20.418817Z","iopub.status.idle":"2026-02-02T15:01:24.804020Z","shell.execute_reply.started":"2026-02-02T15:01:20.418787Z","shell.execute_reply":"2026-02-02T15:01:24.803061Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Embeddings","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nzett_clf = AutoModelForSequenceClassification.from_pretrained(\n    \"FacebookAI/xlm-roberta-base\",\n    num_labels=7,\n    problem_type=\"multi_label_classification\"\n).to(device)\n\nnew_emb = torch.nn.Embedding(\n    predicted_input_embeddings.size(0),\n    predicted_input_embeddings.size(1),\n    padding_idx=tokA.pad_token_id\n).to(device)\n\nnew_emb.weight.data[:] = predicted_input_embeddings.to(device)\n\nzett_clf.roberta.embeddings.word_embeddings = new_emb\n\nzett_clf.config.vocab_size = tokA.vocab_size\nzett_clf.config.pad_token_id = tokA.pad_token_id\nzett_clf.config.bos_token_id = tokA.bos_token_id\nzett_clf.config.eos_token_id = tokA.eos_token_id\nzett_clf.config.unk_token_id = tokA.unk_token_id\nzett_clf.config.mask_token_id = tokA.mask_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:01:48.420424Z","iopub.status.idle":"2026-02-02T15:01:48.420773Z","shell.execute_reply.started":"2026-02-02T15:01:48.420607Z","shell.execute_reply":"2026-02-02T15:01:48.420627Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# After Zero-Shot Tokenizer Transfer","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n\ntrain_after = train_ds.map(lambda batch: tokA(batch[\"text\"], truncation=True), batched=True)\nval_after = val_ds.map(lambda batch: tokA(batch[\"text\"], truncation=True), batched=True)\n\ncollator_after = DataCollatorWithPadding(tokenizer=tokA)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:01:48.421978Z","iopub.status.idle":"2026-02-02T15:01:48.422243Z","shell.execute_reply.started":"2026-02-02T15:01:48.422113Z","shell.execute_reply":"2026-02-02T15:01:48.422130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args_after = TrainingArguments(\n    output_dir=\"/kaggle/working/emotions\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-5, # 0.0001\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    num_train_epochs=20,\n    weight_decay=0.005,\n    report_to=\"none\",\n    seed=32,\n    fp16=torch.cuda.is_available(),\n)\n\ntrainer_after = Trainer(\n    model=zett_clf,\n    args=args_after,\n    train_dataset=train_after,\n    eval_dataset=val_after,\n    tokenizer=tokA,\n    data_collator=collator_after,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:01:48.423421Z","iopub.status.idle":"2026-02-02T15:01:48.423922Z","shell.execute_reply.started":"2026-02-02T15:01:48.423642Z","shell.execute_reply":"2026-02-02T15:01:48.423670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"After Zett\")\ntrainer_after.train()\nafter_eval = trainer_after.evaluate()\nafter_eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T15:01:48.425296Z","iopub.status.idle":"2026-02-02T15:01:48.425724Z","shell.execute_reply.started":"2026-02-02T15:01:48.425492Z","shell.execute_reply":"2026-02-02T15:01:48.425518Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}}]}
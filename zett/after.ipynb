{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14592870,"sourceType":"datasetVersion","datasetId":9321449},{"sourceId":14643928,"sourceType":"datasetVersion","datasetId":9354574},{"sourceId":14700066,"sourceType":"datasetVersion","datasetId":9390990},{"sourceId":737760,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":562600,"modelId":575190},{"sourceId":738787,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":563439,"modelId":575960}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:02:58.931761Z","iopub.execute_input":"2026-02-02T14:02:58.932148Z","iopub.status.idle":"2026-02-02T14:02:58.937843Z","shell.execute_reply.started":"2026-02-02T14:02:58.932115Z","shell.execute_reply":"2026-02-02T14:02:58.936366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"lang-uk/malyuk\", split=\"train\", streaming=True)\n# dataset = dataset[:300000}\n\ntext = []\nfor i, row in enumerate(dataset['text']):\n    if i > 100000:\n        break\n    text.append(row)\n\n# text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:02:58.939672Z","iopub.execute_input":"2026-02-02T14:02:58.939939Z","iopub.status.idle":"2026-02-02T14:03:01.601528Z","shell.execute_reply.started":"2026-02-02T14:02:58.939911Z","shell.execute_reply":"2026-02-02T14:03:01.600527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:01.626231Z","iopub.execute_input":"2026-02-02T14:03:01.626636Z","iopub.status.idle":"2026-02-02T14:03:01.641526Z","shell.execute_reply.started":"2026-02-02T14:03:01.626609Z","shell.execute_reply":"2026-02-02T14:03:01.640073Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training base vocab","metadata":{}},{"cell_type":"code","source":"from tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom tokenizers.trainers import BpeTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\nfrom transformers import PreTrainedTokenizerFast\n\n# text = court[0].astype(str).tolist()\ntok = Tokenizer(BPE(unk_token=\"<unk>\"))\ntok.pre_tokenizer = Whitespace()\n\ntrainer = BpeTrainer(\n    vocab_size=40000,\n    min_frequency=2,\n    special_tokens=[\"<s>\", \"</s>\", \"<pad>\", \"<unk>\", \"<mask>\"]\n)\n\ntok.train_from_iterator(text, trainer=trainer)\n\ntokA = PreTrainedTokenizerFast(\n    tokenizer_object=tok,\n    bos_token=\"<s>\", eos_token=\"</s>\",\n    unk_token=\"<unk>\", sep_token=\"</s>\",\n    cls_token=\"<s>\", pad_token=\"<pad>\", mask_token=\"<mask>\",\n)\n\ntokA.save_pretrained(\"tokA\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:01.642773Z","iopub.execute_input":"2026-02-02T14:03:01.643072Z","iopub.status.idle":"2026-02-02T14:03:06.972142Z","shell.execute_reply.started":"2026-02-02T14:03:01.643046Z","shell.execute_reply":"2026-02-02T14:03:06.970948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokA = AutoTokenizer.from_pretrained(\"/kaggle/working/tokA\", use_fast=True)\nvocab = tokA.get_vocab()\ntokens = [t for t, _id in sorted(vocab.items(), key=lambda x: x[1])]\ntokens[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:06.973676Z","iopub.execute_input":"2026-02-02T14:03:06.974321Z","iopub.status.idle":"2026-02-02T14:03:14.078701Z","shell.execute_reply.started":"2026-02-02T14:03:06.974236Z","shell.execute_reply":"2026-02-02T14:03:14.077464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Due to problen with \"from zett.utils import get_surface_form_matrix\" we tokk function \"get_surface_form_matrix\" from Zett repo in GitHub.","metadata":{}},{"cell_type":"code","source":"CHARS_TO_BYTES = {\n    \"Ā\": 0,\n    \"ā\": 1,\n    \"Ă\": 2,\n    \"ă\": 3,\n    \"Ą\": 4,\n    \"ą\": 5,\n    \"Ć\": 6,\n    \"ć\": 7,\n    \"Ĉ\": 8,\n    \"ĉ\": 9,\n    \"Ċ\": 10,\n    \"ċ\": 11,\n    \"Č\": 12,\n    \"č\": 13,\n    \"Ď\": 14,\n    \"ď\": 15,\n    \"Đ\": 16,\n    \"đ\": 17,\n    \"Ē\": 18,\n    \"ē\": 19,\n    \"Ĕ\": 20,\n    \"ĕ\": 21,\n    \"Ė\": 22,\n    \"ė\": 23,\n    \"Ę\": 24,\n    \"ę\": 25,\n    \"Ě\": 26,\n    \"ě\": 27,\n    \"Ĝ\": 28,\n    \"ĝ\": 29,\n    \"Ğ\": 30,\n    \"ğ\": 31,\n    \"Ġ\": 32,\n    \"!\": 33,\n    '\"': 34,\n    \"#\": 35,\n    \"$\": 36,\n    \"%\": 37,\n    \"&\": 38,\n    \"'\": 39,\n    \"(\": 40,\n    \")\": 41,\n    \"*\": 42,\n    \"+\": 43,\n    \",\": 44,\n    \"-\": 45,\n    \".\": 46,\n    \"/\": 47,\n    \"0\": 48,\n    \"1\": 49,\n    \"2\": 50,\n    \"3\": 51,\n    \"4\": 52,\n    \"5\": 53,\n    \"6\": 54,\n    \"7\": 55,\n    \"8\": 56,\n    \"9\": 57,\n    \":\": 58,\n    \";\": 59,\n    \"<\": 60,\n    \"=\": 61,\n    \">\": 62,\n    \"?\": 63,\n    \"@\": 64,\n    \"A\": 65,\n    \"B\": 66,\n    \"C\": 67,\n    \"D\": 68,\n    \"E\": 69,\n    \"F\": 70,\n    \"G\": 71,\n    \"H\": 72,\n    \"I\": 73,\n    \"J\": 74,\n    \"K\": 75,\n    \"L\": 76,\n    \"M\": 77,\n    \"N\": 78,\n    \"O\": 79,\n    \"P\": 80,\n    \"Q\": 81,\n    \"R\": 82,\n    \"S\": 83,\n    \"T\": 84,\n    \"U\": 85,\n    \"V\": 86,\n    \"W\": 87,\n    \"X\": 88,\n    \"Y\": 89,\n    \"Z\": 90,\n    \"[\": 91,\n    \"\\\\\": 92,\n    \"]\": 93,\n    \"^\": 94,\n    \"_\": 95,\n    \"`\": 96,\n    \"a\": 97,\n    \"b\": 98,\n    \"c\": 99,\n    \"d\": 100,\n    \"e\": 101,\n    \"f\": 102,\n    \"g\": 103,\n    \"h\": 104,\n    \"i\": 105,\n    \"j\": 106,\n    \"k\": 107,\n    \"l\": 108,\n    \"m\": 109,\n    \"n\": 110,\n    \"o\": 111,\n    \"p\": 112,\n    \"q\": 113,\n    \"r\": 114,\n    \"s\": 115,\n    \"t\": 116,\n    \"u\": 117,\n    \"v\": 118,\n    \"w\": 119,\n    \"x\": 120,\n    \"y\": 121,\n    \"z\": 122,\n    \"{\": 123,\n    \"|\": 124,\n    \"}\": 125,\n    \"~\": 126,\n    \"ġ\": 127,\n    \"Ģ\": 128,\n    \"ģ\": 129,\n    \"Ĥ\": 130,\n    \"ĥ\": 131,\n    \"Ħ\": 132,\n    \"ħ\": 133,\n    \"Ĩ\": 134,\n    \"ĩ\": 135,\n    \"Ī\": 136,\n    \"ī\": 137,\n    \"Ĭ\": 138,\n    \"ĭ\": 139,\n    \"Į\": 140,\n    \"į\": 141,\n    \"İ\": 142,\n    \"ı\": 143,\n    \"Ĳ\": 144,\n    \"ĳ\": 145,\n    \"Ĵ\": 146,\n    \"ĵ\": 147,\n    \"Ķ\": 148,\n    \"ķ\": 149,\n    \"ĸ\": 150,\n    \"Ĺ\": 151,\n    \"ĺ\": 152,\n    \"Ļ\": 153,\n    \"ļ\": 154,\n    \"Ľ\": 155,\n    \"ľ\": 156,\n    \"Ŀ\": 157,\n    \"ŀ\": 158,\n    \"Ł\": 159,\n    \"ł\": 160,\n    \"¡\": 161,\n    \"¢\": 162,\n    \"£\": 163,\n    \"¤\": 164,\n    \"¥\": 165,\n    \"¦\": 166,\n    \"§\": 167,\n    \"¨\": 168,\n    \"©\": 169,\n    \"ª\": 170,\n    \"«\": 171,\n    \"¬\": 172,\n    \"Ń\": 173,\n    \"®\": 174,\n    \"¯\": 175,\n    \"°\": 176,\n    \"±\": 177,\n    \"²\": 178,\n    \"³\": 179,\n    \"´\": 180,\n    \"µ\": 181,\n    \"¶\": 182,\n    \"·\": 183,\n    \"¸\": 184,\n    \"¹\": 185,\n    \"º\": 186,\n    \"»\": 187,\n    \"¼\": 188,\n    \"½\": 189,\n    \"¾\": 190,\n    \"¿\": 191,\n    \"À\": 192,\n    \"Á\": 193,\n    \"Â\": 194,\n    \"Ã\": 195,\n    \"Ä\": 196,\n    \"Å\": 197,\n    \"Æ\": 198,\n    \"Ç\": 199,\n    \"È\": 200,\n    \"É\": 201,\n    \"Ê\": 202,\n    \"Ë\": 203,\n    \"Ì\": 204,\n    \"Í\": 205,\n    \"Î\": 206,\n    \"Ï\": 207,\n    \"Ð\": 208,\n    \"Ñ\": 209,\n    \"Ò\": 210,\n    \"Ó\": 211,\n    \"Ô\": 212,\n    \"Õ\": 213,\n    \"Ö\": 214,\n    \"×\": 215,\n    \"Ø\": 216,\n    \"Ù\": 217,\n    \"Ú\": 218,\n    \"Û\": 219,\n    \"Ü\": 220,\n    \"Ý\": 221,\n    \"Þ\": 222,\n    \"ß\": 223,\n    \"à\": 224,\n    \"á\": 225,\n    \"â\": 226,\n    \"ã\": 227,\n    \"ä\": 228,\n    \"å\": 229,\n    \"æ\": 230,\n    \"ç\": 231,\n    \"è\": 232,\n    \"é\": 233,\n    \"ê\": 234,\n    \"ë\": 235,\n    \"ì\": 236,\n    \"í\": 237,\n    \"î\": 238,\n    \"ï\": 239,\n    \"ð\": 240,\n    \"ñ\": 241,\n    \"ò\": 242,\n    \"ó\": 243,\n    \"ô\": 244,\n    \"õ\": 245,\n    \"ö\": 246,\n    \"÷\": 247,\n    \"ø\": 248,\n    \"ù\": 249,\n    \"ú\": 250,\n    \"û\": 251,\n    \"ü\": 252,\n    \"ý\": 253,\n    \"þ\": 254,\n    \"ÿ\": 255,\n}\nBYTES_TO_CHARS = {v: k for k, v in CHARS_TO_BYTES.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:14.080147Z","iopub.execute_input":"2026-02-02T14:03:14.081185Z","iopub.status.idle":"2026-02-02T14:03:14.113698Z","shell.execute_reply.started":"2026-02-02T14:03:14.081149Z","shell.execute_reply":"2026-02-02T14:03:14.112435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_CHARS_PER_TOKEN = 16\n\ndef unicode_to_zett_bytechars(token: str, maxlen: int = MAX_CHARS_PER_TOKEN) -> str:\n    b = token.encode(\"utf-8\", errors=\"replace\")[:maxlen]\n    return \"\".join(BYTES_TO_CHARS[byte] for byte in b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:14.114995Z","iopub.execute_input":"2026-02-02T14:03:14.115417Z","iopub.status.idle":"2026-02-02T14:03:14.159522Z","shell.execute_reply.started":"2026-02-02T14:03:14.115376Z","shell.execute_reply":"2026-02-02T14:03:14.158064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.auto import tqdm\nfrom transformers import ByT5Tokenizer\n\ndef get_surface_form_matrix(\n    tokenizer_or_tokens, maxlen, tokenizer_to_use=None, padding=0, verbose=False\n):\n    # tokens are expected to be byte encoded\n    if isinstance(tokenizer_or_tokens, list):\n        tokens = tokenizer_or_tokens\n    else:\n        tokenizer = tokenizer_or_tokens\n        tokens = tokenizer.convert_ids_to_tokens(range(len(tokenizer)))\n\n    vocab_size = len(tokens)\n    surface_form_matrix = np.full(\n        (vocab_size + padding, maxlen),\n        tokenizer_to_use.pad_token_id if tokenizer_to_use is not None else 0,\n        dtype=np.int32,\n    )\n\n    n_truncated = 0\n\n    for i, token in tqdm(enumerate(tokens), total=vocab_size, disable=not verbose):\n        if token in tokenizer_to_use.all_special_tokens:\n            surface_form_matrix[i, 0] = tokenizer_to_use.convert_tokens_to_ids(token)\n            continue\n\n        token = unicode_to_zett_bytechars(token, maxlen=maxlen)\n        token_bytes = bytes([CHARS_TO_BYTES[c] for c in token])\n\n        if isinstance(tokenizer_to_use, ByT5Tokenizer):\n            ids = tokenizer_to_use.convert_tokens_to_ids([chr(i) for i in token_bytes])\n        else:\n            # assume hn tokenizer uses byte pretokenization\n            ids = [x.id for x in tokenizer_to_use._tokenizer.model.tokenize(token)]\n\n        if len(ids) > maxlen:\n            ids = ids[:maxlen]\n            n_truncated += 1\n\n        surface_form_matrix[i, : len(ids)] = ids\n\n    return surface_form_matrix, n_truncated","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:14.160802Z","iopub.execute_input":"2026-02-02T14:03:14.161450Z","iopub.status.idle":"2026-02-02T14:03:14.186901Z","shell.execute_reply.started":"2026-02-02T14:03:14.161406Z","shell.execute_reply":"2026-02-02T14:03:14.185863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer, AutoModelForMaskedLM\n# from zett.utils import get_surface_form_matrix\n\nbase_model = AutoModelForMaskedLM.from_pretrained(\"FacebookAI/xlm-roberta-base\").to(device).eval()\nhypernet = AutoModel.from_pretrained(\"benjamin/zett-hypernetwork-xlm-roberta-base\", trust_remote_code=True).to(device).eval()\n\nhn_tokenizer = AutoTokenizer.from_pretrained(\"benjamin/zett-hypernetwork-xlm-roberta-base\")\n\nsource_embeddings = base_model.get_input_embeddings().weight.detach()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:14.189965Z","iopub.execute_input":"2026-02-02T14:03:14.190316Z","iopub.status.idle":"2026-02-02T14:03:44.610622Z","shell.execute_reply.started":"2026-02-02T14:03:14.190236Z","shell.execute_reply":"2026-02-02T14:03:44.608697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_in_chunks = []\n\nfor i in range(0, len(tokens), 512):\n    batch_tokens = tokens[i:i+512]\n\n    target_surface_forms, _ = get_surface_form_matrix(\n        batch_tokens, # byte representation of the tokens to predict\n        maxlen=hypernet.config.hn_surface_maxlen,\n        tokenizer_to_use=hn_tokenizer,\n    )\n\n    lang_index = torch.tensor([17], device=device, dtype=torch.long)\n    with torch.no_grad():\n        # the last output is the predicted bias in case the model uses a bias (e.g. XLM-R)\n        predicted_input_embeddings, predicted_output_embeddings, _ = hypernet(\n            torch.from_numpy(target_surface_forms).to(device),\n            source_embeddings=source_embeddings,\n            lang_index=lang_index\n        )\n\n    pred_in_chunks.append(predicted_input_embeddings.detach().cpu())\n\npredicted_input_embeddings = torch.cat(pred_in_chunks, dim=0) # shap: [40000, 768]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.611577Z","iopub.status.idle":"2026-02-02T14:03:44.611887Z","shell.execute_reply.started":"2026-02-02T14:03:44.611748Z","shell.execute_reply":"2026-02-02T14:03:44.611766Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train =  pd.read_csv(\"/kaggle/input/part-3df/train.csv\")\nval = pd.read_csv(\"/kaggle/input/val-emotions/validation-set-sample.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.612712Z","iopub.status.idle":"2026-02-02T14:03:44.613016Z","shell.execute_reply.started":"2026-02-02T14:03:44.612872Z","shell.execute_reply":"2026-02-02T14:03:44.612889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = [\"Joy\", \"Fear\", \"Anger\", \"Sadness\", \"Disgust\", \"Surprise\"]\n\ntrain[\"No\"] = ((train[labels].to_numpy() == 0).all(axis=1)).astype(int)\nval[\"No\"] = ((val[labels].to_numpy() == 0).all(axis=1)).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.613688Z","iopub.status.idle":"2026-02-02T14:03:44.613967Z","shell.execute_reply.started":"2026-02-02T14:03:44.613829Z","shell.execute_reply":"2026-02-02T14:03:44.613844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = [\"Joy\", \"Fear\", \"Anger\", \"Sadness\", \"Disgust\", \"Surprise\", \"No\"]\n\nx_train, x_val = train[\"text\"].astype(str).tolist(), val[\"text\"].astype(str).tolist()\n\ny_train = (train[labels].astype(float).values>0).astype(float).tolist()\ny_val = (val[labels].astype(float).values>0).astype(float).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.616745Z","iopub.status.idle":"2026-02-02T14:03:44.617210Z","shell.execute_reply.started":"2026-02-02T14:03:44.616983Z","shell.execute_reply":"2026-02-02T14:03:44.617011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_ds = Dataset.from_dict({\"text\": x_train, \"labels\": y_train})\nval_ds = Dataset.from_dict({\"text\": x_val, \"labels\": y_val})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.618188Z","iopub.status.idle":"2026-02-02T14:03:44.618592Z","shell.execute_reply.started":"2026-02-02T14:03:44.618417Z","shell.execute_reply":"2026-02-02T14:03:44.618435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ndef sigmoid(x):\n   return 1/(1 + np.exp(-x))\n    \ndef compute_metrics(eval_pred):\n    predictions, y_true = eval_pred.predictions, eval_pred.label_ids\n    y_pred = sigmoid(predictions)\n    y_pred = (y_pred>0.2).astype(float)\n    y_true = (y_true>0).astype(float)\n        \n    clf_dict = classification_report(\n        y_true, y_pred, \n        target_names=[\"Joy\", \"Fear\", \"Anger\", \"Sadness\", \"Disgust\", \"Surprise\", \"No\"],\n        zero_division=0, \n        output_dict=True)\n\n    accuracy_thresh = float(np.mean(np.all(y_pred == y_true, axis=1)))\n    return {\"accuracy_thresh\": accuracy_thresh, \n            \"micro f1\": clf_dict['micro avg']['f1-score'], \n            \"macro f1\": clf_dict['macro avg']['f1-score']}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.623814Z","iopub.status.idle":"2026-02-02T14:03:44.624377Z","shell.execute_reply.started":"2026-02-02T14:03:44.624077Z","shell.execute_reply":"2026-02-02T14:03:44.624107Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Embeddings","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nzett_clf = AutoModelForSequenceClassification.from_pretrained(\n    \"FacebookAI/xlm-roberta-base\",\n    num_labels=7,\n    problem_type=\"multi_label_classification\"\n).to(device)\n\nnew_emb = torch.nn.Embedding(\n    predicted_input_embeddings.size(0),\n    predicted_input_embeddings.size(1),\n    padding_idx=tokA.pad_token_id\n).to(device)\n\nnew_emb.weight.data[:] = predicted_input_embeddings.to(device)\n\nzett_clf.roberta.embeddings.word_embeddings = new_emb\n\nzett_clf.config.vocab_size = tokA.vocab_size\nzett_clf.config.pad_token_id = tokA.pad_token_id\nzett_clf.config.bos_token_id = tokA.bos_token_id\nzett_clf.config.eos_token_id = tokA.eos_token_id\nzett_clf.config.unk_token_id = tokA.unk_token_id\nzett_clf.config.mask_token_id = tokA.mask_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.630200Z","iopub.status.idle":"2026-02-02T14:03:44.630585Z","shell.execute_reply.started":"2026-02-02T14:03:44.630434Z","shell.execute_reply":"2026-02-02T14:03:44.630455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# After Zero-Shot Tokenizer Transfer","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n\ntrain_after = train_ds.map(lambda batch: tokA(batch[\"text\"], truncation=True), batched=True)\nval_after = val_ds.map(lambda batch: tokA(batch[\"text\"], truncation=True), batched=True)\n\ncollator_after = DataCollatorWithPadding(tokenizer=tokA)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.632375Z","iopub.status.idle":"2026-02-02T14:03:44.632711Z","shell.execute_reply.started":"2026-02-02T14:03:44.632564Z","shell.execute_reply":"2026-02-02T14:03:44.632584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args_after = TrainingArguments(\n    output_dir=\"/kaggle/working/emotions\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-5, # 0.0001\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    num_train_epochs=20,\n    weight_decay=0.005,\n    report_to=\"none\",\n    seed=32,\n    fp16=torch.cuda.is_available(),\n)\n\ntrainer_after = Trainer(\n    model=zett_clf,\n    args=args_after,\n    train_dataset=train_after,\n    eval_dataset=val_after,\n    tokenizer=tokA,\n    data_collator=collator_after,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.634721Z","iopub.status.idle":"2026-02-02T14:03:44.635239Z","shell.execute_reply.started":"2026-02-02T14:03:44.634990Z","shell.execute_reply":"2026-02-02T14:03:44.635023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"After Zett\")\ntrainer_after.train()\nafter_eval = trainer_after.evaluate()\nafter_eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.637210Z","iopub.status.idle":"2026-02-02T14:03:44.637678Z","shell.execute_reply.started":"2026-02-02T14:03:44.637518Z","shell.execute_reply":"2026-02-02T14:03:44.637540Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"after = {k: f\"{v:.2f}\" for k, v in after_eval.items()}\nprint(f'\\n\\nAfter Zett {after} \\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T14:03:44.639377Z","iopub.status.idle":"2026-02-02T14:03:44.639739Z","shell.execute_reply.started":"2026-02-02T14:03:44.639592Z","shell.execute_reply":"2026-02-02T14:03:44.639611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}}]}